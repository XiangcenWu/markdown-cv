# Your Name
**Deep Learning Engineer / AI Researcher** [Email](mailto:your.email@example.com) | [GitHub](https://github.com/XiangcenWu) | [LinkedIn](https://linkedin.com/in/yourprofile) | [Portfolio/HuggingFace](https://huggingface.co/yourname)

---

## Professional Summary
Results-driven Deep Learning Engineer with expertise in **[Computer Vision / NLP / Generative AI]**. Proficient in building, training, and deploying large-scale neural networks using **PyTorch** and **TensorFlow**. Experienced in optimizing model latency and accuracy for production-level AI applications.

---

## Technical Skills
* **Frameworks:** PyTorch, TensorFlow, JAX, Hugging Face Transformers, Keras.
* **Languages:** Python (Expert), C++, SQL, Bash.
* **Deep Learning:** CNNs, Transformers, LLMs, GANs, Diffusion Models, Reinforcement Learning.
* **Tools & MLOps:** Docker, Kubernetes, Weights & Biases, MLflow, ONNX, TensorRT, Git.
* **Cloud:** AWS (SageMaker), GCP (Vertex AI), Azure ML.

---

## Research & Work Experience

### **[Role, e.g., AI Research Intern]** | [Company/University Name]
*Month Year – Present*
* Developed a **[Model Type, e.g., Transformer-based]** architecture for **[Task, e.g., time-series forecasting]**, resulting in a **[XX]% increase in accuracy** over the baseline.
* Optimized model inference time by **[XX]%** using **[Technique, e.g., Quantization or Pruning]** for deployment on edge devices.
* Collaborated with a cross-functional team to curate a dataset of **[Size, e.g., 1M+]** samples, improving model robustness against out-of-distribution data.

### **[Role, e.g., Machine Learning Engineer]** | [Previous Company]
*Month Year – Month Year*
* Implemented an automated data pipeline using **[Tool, e.g., Apache Airflow]** that reduced data preprocessing time by **[XX]** hours per week.
* Trained and fine-tuned **[Specific Model, e.g., ResNet-101 or BERT]** for **[Industry Problem]**, achieving state-of-the-art results on internal benchmarks.

---

## Selected Projects

### **[Project Name, e.g., Generative Image Synthesis with GANs]**
* **Tech Stack:** PyTorch, TorchVision, CUDA.
* Built a custom GAN architecture to generate high-resolution images; implemented **Frechet Inception Distance (FID)** to quantify image quality.
* [Link to Repo/Demo]

### **[Project Name, e.g., Distributed Training Pipeline for LLMs]**
* **Tech Stack:** PyTorch Distributed, Deepspeed, Hugging Face.
* Architected a distributed training script to fine-tune a 7B parameter model across 4x A100 GPUs, utilizing **ZeRO optimization**.

---

## Education
* **[Degree Name, e.g., MS in Computer Science]** | [University Name] | *Graduation Year*
    * *Relevant Coursework:* Neural Networks, Computer Vision, Optimization for ML.
    * *Thesis:* [Title of your thesis or major research project].

---

## Publications / Certifications
* **[Publication Title]** – [Conference Name, e.g., CVPR/NeurIPS] (Year)
* **TensorFlow Developer Certificate** – Google
* **Deep Learning Specialization** – Coursera (DeepLearning.AI)
